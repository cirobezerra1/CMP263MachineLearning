{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b4692a-aa85-4d68-bdd6-2016769c9757",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 00.Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0589ad1-f2b5-4bc9-8430-2a6c40378d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras_tuner import RandomSearch\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e38e817-e14a-4ea1-8fba-daf6dd06bfe3",
   "metadata": {},
   "source": [
    "# 01.Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e23448b-9c27-4954-97e3-b0094d6cef32",
   "metadata": {},
   "source": [
    "## 01.01 Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49d87d56-96c1-4366-a634-cf0310eda6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['date', 'hospitalizations', 'heat_index', 'heat_index_sum', 'heat_index_std', 'heat_index99','heat_index95', 'temperature_mean', 'temperature_max',\n",
    "           'temperature_min', 'wind_speed_mean', 'humidity_mean','lag_heat_index_1', 'lag_heat_index_2', 'lag_heat_index_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e43dc47d-55e8-47f5-9aff-7bd0cdc093ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_date = \"2017-01-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd56694-e132-479d-a720-17a7dd97c3cd",
   "metadata": {},
   "source": [
    "## 01.02 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbb0a1d7-2f52-4664-9741-486ee7e7f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e22c06f1-b044-445d-b54e-72d06782ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_date, target_variable):\n",
    "    # separação por tempo\n",
    "    df_train = df[df.index < test_date]\n",
    "    df_test  = df[df.index >= test_date]\n",
    "\n",
    "    # remoção da variável target\n",
    "    y_train = df_train[target_variable]\n",
    "    y_test  = df_test[target_variable]\n",
    "\n",
    "    df_train = df_train.drop(columns=target_variable).copy()\n",
    "    df_test  = df_test.drop(columns=target_variable).copy()\n",
    "\n",
    "    print(df_train.shape, y_train.shape)\n",
    "    print(df_test.shape, y_test.shape)\n",
    "\n",
    "    return df_train, df_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7b2b78f-5fcd-41fd-a037-7c923c7f41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_normalization(df_train, df_test, y_train, y_test):\n",
    "    # Para as features\n",
    "    scaler               = MinMaxScaler(feature_range=(0, 1))\n",
    "    df_train_scaled      = scaler.fit_transform(df_train)\n",
    "    df_test_scaled       = scaler.transform(df_test)\n",
    "\n",
    "    # Para a variável alvo\n",
    "    scaler_target       = MinMaxScaler(feature_range=(0, 1))\n",
    "    y_train_scaled      = scaler_target.fit_transform(y_train.to_frame())\n",
    "    y_test_scaled       = scaler_target.transform(y_test.to_frame())\n",
    "\n",
    "    print(df_train_scaled.shape, y_train_scaled.shape)\n",
    "    print(df_test_scaled.shape, y_test_scaled.shape)\n",
    "\n",
    "    return scaler, scaler_target, df_train_scaled, df_test_scaled, y_train_scaled, y_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd2e7e17-198d-416d-8bd9-2485b46f5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reconversion(scaler, scaler_target, df_train_scaled, df_test_scaled, y_train_scaled, y_test_scaled, y_pred):\n",
    "    df_train_original = scaler.inverse_transform(df_train_scaled)\n",
    "    df_test_original = scaler.inverse_transform(df_test_scaled)\n",
    "\n",
    "    y_train_original = scaler_target.inverse_transform(y_train_scaled)\n",
    "    y_test_original = scaler_target.inverse_transform(y_test_scaled)\n",
    "    y_pred_original = scaler_target.inverse_transform(y_pred)\n",
    "\n",
    "    return df_train_original, df_test_original, y_train_original, y_test_original, y_pred_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f7ed204-dff3-4610-ae13-3b4b6d188d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y, predicted):\n",
    "    mae = mean_absolute_error(y, predicted)\n",
    "    mse = mean_squared_error(y, predicted)\n",
    "    rmse = mean_squared_error(y, predicted)\n",
    "    mape = np.mean(np.abs((y - predicted) / y)) * 100\n",
    "    r2 = r2_score(y, predicted)\n",
    "    return mae, mse, rmse, mape, r2\n",
    "\n",
    "def print_metrics(y, predicted):\n",
    "    mae, mse, rmse, mape, r2 = metrics(y, predicted)\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "    print(f\"R-Squared (R²): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc9242c8-74b6-4ac8-83c8-ab835bf9d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    # LSTM layers with variable number of units\n",
    "    model.add(LSTM(units=hp.Int('units_layer1', min_value=10, max_value=100, step=5), input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    # model.add(LSTM(units=hp.Int('units_layer2', min_value=10, max_value=100, step=5), return_sequences=True))\n",
    "    # model.add(LSTM(units=hp.Int('units_layer3', min_value=10, max_value=100, step=5)))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4])),\n",
    "        loss='mse'\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f34482-b936-4961-87b8-f04de0a18751",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 02.Importing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ed4d93c-b046-487d-97b4-341a0eb255a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospitalizations</th>\n",
       "      <th>heat_index</th>\n",
       "      <th>heat_index_sum</th>\n",
       "      <th>heat_index_std</th>\n",
       "      <th>heat_index99</th>\n",
       "      <th>heat_index95</th>\n",
       "      <th>temperature_mean</th>\n",
       "      <th>temperature_max</th>\n",
       "      <th>temperature_min</th>\n",
       "      <th>wind_speed_mean</th>\n",
       "      <th>humidity_mean</th>\n",
       "      <th>lag_heat_index_1</th>\n",
       "      <th>lag_heat_index_2</th>\n",
       "      <th>lag_heat_index_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-12-01</th>\n",
       "      <td>4266.0</td>\n",
       "      <td>24.154261</td>\n",
       "      <td>17970.77</td>\n",
       "      <td>4.999719</td>\n",
       "      <td>37.8966</td>\n",
       "      <td>33.5380</td>\n",
       "      <td>23.575000</td>\n",
       "      <td>35.4</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1.826613</td>\n",
       "      <td>70.836022</td>\n",
       "      <td>21.132403</td>\n",
       "      <td>19.318992</td>\n",
       "      <td>15.300694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-01</th>\n",
       "      <td>4032.0</td>\n",
       "      <td>26.316156</td>\n",
       "      <td>19579.22</td>\n",
       "      <td>4.452698</td>\n",
       "      <td>37.8471</td>\n",
       "      <td>34.6685</td>\n",
       "      <td>25.136962</td>\n",
       "      <td>35.4</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.777016</td>\n",
       "      <td>75.375000</td>\n",
       "      <td>24.154261</td>\n",
       "      <td>21.132403</td>\n",
       "      <td>19.318992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-01</th>\n",
       "      <td>3888.0</td>\n",
       "      <td>27.119464</td>\n",
       "      <td>18224.28</td>\n",
       "      <td>4.274063</td>\n",
       "      <td>37.7548</td>\n",
       "      <td>35.3940</td>\n",
       "      <td>25.691071</td>\n",
       "      <td>34.2</td>\n",
       "      <td>20.2</td>\n",
       "      <td>1.916518</td>\n",
       "      <td>76.424107</td>\n",
       "      <td>26.316156</td>\n",
       "      <td>24.154261</td>\n",
       "      <td>21.132403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03-01</th>\n",
       "      <td>3658.0</td>\n",
       "      <td>26.113387</td>\n",
       "      <td>19428.36</td>\n",
       "      <td>4.220196</td>\n",
       "      <td>36.7670</td>\n",
       "      <td>34.4155</td>\n",
       "      <td>24.985349</td>\n",
       "      <td>34.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>1.629704</td>\n",
       "      <td>76.383065</td>\n",
       "      <td>27.119464</td>\n",
       "      <td>26.316156</td>\n",
       "      <td>24.154261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-04-01</th>\n",
       "      <td>4022.0</td>\n",
       "      <td>21.383903</td>\n",
       "      <td>15396.41</td>\n",
       "      <td>3.427034</td>\n",
       "      <td>31.0030</td>\n",
       "      <td>28.0215</td>\n",
       "      <td>21.038333</td>\n",
       "      <td>30.8</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1.455139</td>\n",
       "      <td>81.152778</td>\n",
       "      <td>26.113387</td>\n",
       "      <td>27.119464</td>\n",
       "      <td>26.316156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-01</th>\n",
       "      <td>3172.0</td>\n",
       "      <td>16.708185</td>\n",
       "      <td>12430.89</td>\n",
       "      <td>5.357643</td>\n",
       "      <td>33.1822</td>\n",
       "      <td>27.3330</td>\n",
       "      <td>16.684946</td>\n",
       "      <td>32.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1.345027</td>\n",
       "      <td>85.837366</td>\n",
       "      <td>22.136556</td>\n",
       "      <td>25.621075</td>\n",
       "      <td>27.636221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-01</th>\n",
       "      <td>3640.0</td>\n",
       "      <td>17.283889</td>\n",
       "      <td>12444.40</td>\n",
       "      <td>5.390826</td>\n",
       "      <td>29.7834</td>\n",
       "      <td>26.8025</td>\n",
       "      <td>17.371111</td>\n",
       "      <td>31.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.265139</td>\n",
       "      <td>80.636111</td>\n",
       "      <td>16.708185</td>\n",
       "      <td>22.136556</td>\n",
       "      <td>25.621075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-07-01</th>\n",
       "      <td>3689.0</td>\n",
       "      <td>13.313495</td>\n",
       "      <td>9905.24</td>\n",
       "      <td>4.740495</td>\n",
       "      <td>26.8167</td>\n",
       "      <td>21.7780</td>\n",
       "      <td>13.736022</td>\n",
       "      <td>28.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.123387</td>\n",
       "      <td>81.887097</td>\n",
       "      <td>17.283889</td>\n",
       "      <td>16.708185</td>\n",
       "      <td>22.136556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01</th>\n",
       "      <td>3846.0</td>\n",
       "      <td>15.274395</td>\n",
       "      <td>11364.15</td>\n",
       "      <td>5.299870</td>\n",
       "      <td>28.9485</td>\n",
       "      <td>24.4525</td>\n",
       "      <td>15.594758</td>\n",
       "      <td>31.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.394892</td>\n",
       "      <td>78.956989</td>\n",
       "      <td>13.313495</td>\n",
       "      <td>17.283889</td>\n",
       "      <td>16.708185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-01</th>\n",
       "      <td>3426.0</td>\n",
       "      <td>18.789722</td>\n",
       "      <td>13528.60</td>\n",
       "      <td>4.423471</td>\n",
       "      <td>31.8239</td>\n",
       "      <td>26.9330</td>\n",
       "      <td>18.740278</td>\n",
       "      <td>33.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.534722</td>\n",
       "      <td>80.148611</td>\n",
       "      <td>15.274395</td>\n",
       "      <td>13.313495</td>\n",
       "      <td>17.283889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            hospitalizations  heat_index  heat_index_sum  heat_index_std  \\\n",
       "date                                                                       \n",
       "2000-12-01            4266.0   24.154261        17970.77        4.999719   \n",
       "2001-01-01            4032.0   26.316156        19579.22        4.452698   \n",
       "2001-02-01            3888.0   27.119464        18224.28        4.274063   \n",
       "2001-03-01            3658.0   26.113387        19428.36        4.220196   \n",
       "2001-04-01            4022.0   21.383903        15396.41        3.427034   \n",
       "...                      ...         ...             ...             ...   \n",
       "2024-05-01            3172.0   16.708185        12430.89        5.357643   \n",
       "2024-06-01            3640.0   17.283889        12444.40        5.390826   \n",
       "2024-07-01            3689.0   13.313495         9905.24        4.740495   \n",
       "2024-08-01            3846.0   15.274395        11364.15        5.299870   \n",
       "2024-09-01            3426.0   18.789722        13528.60        4.423471   \n",
       "\n",
       "            heat_index99  heat_index95  temperature_mean  temperature_max  \\\n",
       "date                                                                        \n",
       "2000-12-01       37.8966       33.5380         23.575000             35.4   \n",
       "2001-01-01       37.8471       34.6685         25.136962             35.4   \n",
       "2001-02-01       37.7548       35.3940         25.691071             34.2   \n",
       "2001-03-01       36.7670       34.4155         24.985349             34.4   \n",
       "2001-04-01       31.0030       28.0215         21.038333             30.8   \n",
       "...                  ...           ...               ...              ...   \n",
       "2024-05-01       33.1822       27.3330         16.684946             32.5   \n",
       "2024-06-01       29.7834       26.8025         17.371111             31.5   \n",
       "2024-07-01       26.8167       21.7780         13.736022             28.9   \n",
       "2024-08-01       28.9485       24.4525         15.594758             31.1   \n",
       "2024-09-01       31.8239       26.9330         18.740278             33.7   \n",
       "\n",
       "            temperature_min  wind_speed_mean  humidity_mean  lag_heat_index_1  \\\n",
       "date                                                                            \n",
       "2000-12-01             13.4         1.826613      70.836022         21.132403   \n",
       "2001-01-01             17.0         1.777016      75.375000         24.154261   \n",
       "2001-02-01             20.2         1.916518      76.424107         26.316156   \n",
       "2001-03-01             16.3         1.629704      76.383065         27.119464   \n",
       "2001-04-01             11.9         1.455139      81.152778         26.113387   \n",
       "...                     ...              ...            ...               ...   \n",
       "2024-05-01              7.1         1.345027      85.837366         22.136556   \n",
       "2024-06-01              4.6         1.265139      80.636111         16.708185   \n",
       "2024-07-01              3.4         1.123387      81.887097         17.283889   \n",
       "2024-08-01              4.5         1.394892      78.956989         13.313495   \n",
       "2024-09-01              9.0         1.534722      80.148611         15.274395   \n",
       "\n",
       "            lag_heat_index_2  lag_heat_index_3  \n",
       "date                                            \n",
       "2000-12-01         19.318992         15.300694  \n",
       "2001-01-01         21.132403         19.318992  \n",
       "2001-02-01         24.154261         21.132403  \n",
       "2001-03-01         26.316156         24.154261  \n",
       "2001-04-01         27.119464         26.316156  \n",
       "...                      ...               ...  \n",
       "2024-05-01         25.621075         27.636221  \n",
       "2024-06-01         22.136556         25.621075  \n",
       "2024-07-01         16.708185         22.136556  \n",
       "2024-08-01         17.283889         16.708185  \n",
       "2024-09-01         13.313495         17.283889  \n",
       "\n",
       "[286 rows x 14 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('../../Preprocessing/dataset.csv', \n",
    "                   header=0, \n",
    "                   index_col=0,\n",
    "                   usecols=features)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0aa0d8ae-c422-482b-b54e-f229b5613c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286, 14)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea2871-53cc-49eb-a9d0-8987203a92ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 03.Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb324cf-3bf2-455a-84f5-d3ea0c0fd568",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 03.01 Remoção ano 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66b1015a-6011-44ea-88fb-d1c8a54c8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset.index < \"2020-01-01\"]\n",
    "\n",
    "test_start_date = '2017-01-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040f61da-a1d0-4ba0-b9fb-a8e8efafeb78",
   "metadata": {},
   "source": [
    "# 04.Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b2684-8837-413d-9017-8d12e0b13b6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 04.01 Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d428351-8973-4f43-8b14-15077e429614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 13) (193,)\n",
      "(36, 13) (36,)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test, y_train, y_test = train_test_split(dataset, test_start_date, 'hospitalizations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b97f56-a01b-48a2-a627-b491bf9a5b13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 04.02 Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20cfe4a9-61fb-42ee-aab3-8add8b5b1164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 13) (193, 1)\n",
      "(36, 13) (36, 1)\n"
     ]
    }
   ],
   "source": [
    "scaler, scaler_target, df_train_scaled, df_test_scaled, y_train_scaled, y_test_scaled = data_normalization(df_train, df_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83217a51-d609-466b-9a2a-cfcd174fa0d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 04.03 Reshape input to be 3D [samples, timesteps, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f46156c-b902-49e2-b5c7-88c8ac74fed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 1, 13) (193, 1) (36, 1, 13) (36, 1)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = df_train_scaled.reshape((df_train_scaled.shape[0], 1, df_train_scaled.shape[1]))\n",
    "test_X = df_test_scaled.reshape((df_test_scaled.shape[0], 1, df_test_scaled.shape[1]))\n",
    "\n",
    "print(train_X.shape, y_train_scaled.shape, test_X.shape, y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c274b8d-214b-435e-b966-92b908226534",
   "metadata": {},
   "source": [
    "## 04.04 Recurrent network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdfe854-02d0-4d44-8e9c-ced2f9b45773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "15                |15                |units_layer1\n",
      "80                |80                |units_layer2\n",
      "45                |45                |units_layer3\n",
      "0.001             |0.001             |learning_rate\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thiery/.local/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 175ms/step - loss: 0.2476 - val_loss: 0.0768\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2169 - val_loss: 0.0580\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1851 - val_loss: 0.0364\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1367 - val_loss: 0.0175\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0915 - val_loss: 0.0250\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0459 - val_loss: 0.0909\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0525 - val_loss: 0.1000\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0486 - val_loss: 0.0509\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0417 - val_loss: 0.0302\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0454 - val_loss: 0.0347\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0484 - val_loss: 0.0421\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0406 - val_loss: 0.0495\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0395 - val_loss: 0.0487\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0414 - val_loss: 0.0409\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0399 - val_loss: 0.0387\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0404 - val_loss: 0.0434\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0377 - val_loss: 0.0334\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0416 - val_loss: 0.0285\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0389 - val_loss: 0.0402\n",
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 125ms/step - loss: 0.2285 - val_loss: 0.0714\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.2024 - val_loss: 0.0493\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1802 - val_loss: 0.0261\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1193 - val_loss: 0.0134\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0709 - val_loss: 0.0448\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0434 - val_loss: 0.0878\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0479 - val_loss: 0.0676\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0433 - val_loss: 0.0509\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0381 - val_loss: 0.0354\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0393 - val_loss: 0.0383\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0374 - val_loss: 0.0355\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0388 - val_loss: 0.0438\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0344 - val_loss: 0.0472\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0373 - val_loss: 0.0415\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0342 - val_loss: 0.0373\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0360 - val_loss: 0.0339\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0372 - val_loss: 0.0462\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0302 - val_loss: 0.0475\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0337 - val_loss: 0.0444\n",
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 120ms/step - loss: 0.2458 - val_loss: 0.0753\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2019 - val_loss: 0.0557\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1945 - val_loss: 0.0336\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1234 - val_loss: 0.0155\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0842 - val_loss: 0.0280\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0497 - val_loss: 0.0864\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0487 - val_loss: 0.0705\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0394 - val_loss: 0.0450\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0394 - val_loss: 0.0315\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0467 - val_loss: 0.0278\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0417 - val_loss: 0.0445\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0394 - val_loss: 0.0682\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0415 - val_loss: 0.0597\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0378 - val_loss: 0.0443\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0353 - val_loss: 0.0376\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0375 - val_loss: 0.0368\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0379 - val_loss: 0.0406\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0358 - val_loss: 0.0479\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0327 - val_loss: 0.0610\n",
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 148ms/step - loss: 0.2504 - val_loss: 0.0750\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2066 - val_loss: 0.0549\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1760 - val_loss: 0.0324\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.1372 - val_loss: 0.0148\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0758 - val_loss: 0.0278\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0474 - val_loss: 0.0806\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0472 - val_loss: 0.0680\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0466 - val_loss: 0.0419\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0401 - val_loss: 0.0403\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0419 - val_loss: 0.0552\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0385 - val_loss: 0.0688\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0409 - val_loss: 0.0567\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0394 - val_loss: 0.0472\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0363 - val_loss: 0.0500\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0369 - val_loss: 0.0437\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0334 - val_loss: 0.0425\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0357 - val_loss: 0.0338\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0354 - val_loss: 0.0401\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0359 - val_loss: 0.0453\n",
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "# Configuring Random Search\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,  # Number of combinations to be tested\n",
    "    executions_per_trial=5,\n",
    "    directory='my_dir',\n",
    "    project_name='lstm_tuning'\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "# Perform the search\n",
    "tuner.search(train_X, y_train_scaled, epochs=50, validation_data=(test_X, y_test_scaled), callbacks=[early_stopping])\n",
    "\n",
    "# Best set of hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"Better number of LSTM units in the first layer: {best_hps.get('units_layer1')}\")\n",
    "print(f\"Melhor taxa de aprendizado: {best_hps.get('learning_rate')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb36232-7fcb-481b-844a-f86410ccc966",
   "metadata": {},
   "source": [
    "### 04.04.01 Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f781b3b-4ee7-4bec-88ea-e00467d90409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(20, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, \n",
    "                    y_train_scaled, \n",
    "                    epochs=150, \n",
    "                    batch_size=12, \n",
    "                    validation_data=(test_X, y_test_scaled), \n",
    "                    verbose=2, \n",
    "                    callbacks=[early_stopping],\n",
    "                    shuffle=False)\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a440f3e-bd02-4049-87a7-0ac9dc77ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777e6d28-db4a-4b4e-8b9d-556c9bdbc3bd",
   "metadata": {},
   "source": [
    "### 04.04.02 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce2f3e-a406-42c7-b1fc-82f1e72e0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "# invert scaling for forecast\n",
    "y_pred = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "y_pred = scaler_target.inverse_transform(y_pred)\n",
    "y_pred = y_pred[:,0]\n",
    "\n",
    "# invert scaling for actual\n",
    "test_y = y_test_scaled.reshape((len(y_test_scaled), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler_target.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "\n",
    "# calculate RMSE\n",
    "print_metrics(inv_y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b323aa-6037-4f37-9d15-f9e029faac9d",
   "metadata": {},
   "source": [
    "### 04.04.03 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b22097-a808-4162-b7ae-a9346afac465",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_train = pd.to_datetime(dataset.index)\n",
    "index_test = dataset.tail(len(y_pred)).index\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dataset.index, dataset['hospitalizations'], label='Train')\n",
    "plt.plot(index_test, inv_y, color='green', label='Test')\n",
    "plt.plot(index_test, y_pred, color='red', label='Predicted')\n",
    "plt.title(\"Actual vs predicted\")\n",
    "plt.xlabel('years')\n",
    "plt.ylabel('mortality_rate')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
